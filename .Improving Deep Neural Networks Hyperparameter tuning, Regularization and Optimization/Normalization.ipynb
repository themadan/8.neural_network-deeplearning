{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWtdi9nZ53FY",
        "colab_type": "text"
      },
      "source": [
        "# Normalization \n",
        "* why normalization ?\n",
        " If we don't ,higher value dominant lower values,making the lower unless in the dataset .Therefor ,the network will be unstable, and the exploding gradient problem might happen as well .\n",
        " Moreover ,the training speed would decrease .\n",
        " Therefor,all our data should be on the same scale.\n",
        "\n",
        " * 1.Normalization(min-max normalization)\n",
        " * 2.Standardization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y11ynI8xstpO",
        "colab_type": "text"
      },
      "source": [
        "# 1.Batch normalization\n",
        "* We normalize each feature (each neuron) in a layer according to the batch of samples.The mean and standard deviation are calculate across a batch of sample.\n",
        "* vanyasi k bugenxa vanda feature (=column of array) array ko column ko mean or   or standard deviation nikalni.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ncEXNLdXs9M5",
        "colab_type": "text"
      },
      "source": [
        "# 2.Layer Normalization\n",
        "\n",
        "* We normalize each feature(each neuron)\n",
        "in a layer according to the features in that layer .The mean and standard deviation are calculate across the feature of a layer (across the outputs of a layer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLlnb1QmvLlq",
        "colab_type": "text"
      },
      "source": [
        "# 3.Genetic Grid Search\n",
        "Same concept.The following steps are used.\n",
        "* Randomly choose hyperparameters.\n",
        "* Calculate loss.\n",
        "* Choose some amount of models with the lowest error.\n",
        "* Create new models based on the best models from the previous generation and slightly change their hyperparameters.These new models will contain the previous models and new generated mosels in some proportion,for example,50/50.\n",
        "* Calculate loss,sort the models and repeat the while process again."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XE-St3P0wfFS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}